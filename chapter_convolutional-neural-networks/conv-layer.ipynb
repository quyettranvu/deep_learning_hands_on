{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quyettranvu/deep_learning_hands_on/blob/main/chapter_convolutional-neural-networks/conv-layer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75383284",
      "metadata": {
        "id": "75383284"
      },
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook. Note that running on Colab is experimental, please report a Github\n",
        "issue if you have any problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6ac620a2",
      "metadata": {
        "id": "6ac620a2",
        "outputId": "6145c6c9-98fb-4dbb-8de6-663bfe4ee4f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.3\n",
            "Collecting d2l==1.0.3\n",
            "  Using cached d2l-1.0.3-py3-none-any.whl.metadata (556 bytes)\n",
            "Downloading d2l-1.0.3-py3-none-any.whl (111 kB)\n",
            "Installing collected packages: d2l\n",
            "Successfully installed d2l-1.0.3\n",
            "Collecting numpy<2,>=1.26\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Collecting jupyter\n",
            "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.12/dist-packages (from jupyter) (6.5.7)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.12/dist-packages (from jupyter) (6.6.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.12/dist-packages (from jupyter) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from jupyter) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (from jupyter) (7.7.1)\n",
            "Collecting jupyterlab (from jupyter)\n",
            "  Downloading jupyterlab-4.5.2-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (6.5.1)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (5.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->jupyter)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.9.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->jupyter) (0.2.14)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (5.9.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel->jupyter) (4.5.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter) (0.7.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter) (3.0.16)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter) (25.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter) (5.10.4)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter) (2.0.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter) (0.23.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter) (1.3.3)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from nbclassic>=0.4.7->notebook->jupyter) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (6.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (3.0.3)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (3.2.0)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (0.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (1.5.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (1.4.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook->jupyter) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook->jupyter) (4.26.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter) (0.30.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.12/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (2.14.0)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (4.12.1)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (1.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (3.11)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (4.15.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook->jupyter) (25.1.0)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (4.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (6.0.3)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (0.1.1)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (25.10.0)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (1.3.1)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (2.23)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert->jupyter) (2.8.1)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (1.4.0)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter)\n",
            "  Downloading async_lru-2.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter) (0.28.1)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter)\n",
            "  Downloading jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyterlab-server<3,>=2.28.0 (from jupyterlab->jupyter)\n",
            "  Downloading jupyterlab_server-2.28.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter) (0.16.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter)\n",
            "  Downloading json5-0.13.0-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter) (2.5.0)\n",
            "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m164.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab-4.5.2-py3-none-any.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m182.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.28.0-py3-none-any.whl (59 kB)\n",
            "Downloading async_lru-2.1.0-py3-none-any.whl (6.9 kB)\n",
            "Downloading json5-0.13.0-py3-none-any.whl (36 kB)\n",
            "Downloading jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n",
            "Installing collected packages: numpy, json5, jedi, async-lru, jupyterlab-server, jupyter-lsp, jupyterlab, jupyter\n",
            "\u001b[2K  Attempting uninstall: numpy\n",
            "\u001b[2K    Found existing installation: numpy 2.0.2\n",
            "\u001b[2K    Uninstalling numpy-2.0.2:\n",
            "\u001b[2K      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [jupyter]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "d2l 1.0.3 requires jupyter==1.0.0, but you have jupyter 1.1.1 which is incompatible.\n",
            "d2l 1.0.3 requires matplotlib==3.7.2, but you have matplotlib 3.10.0 which is incompatible.\n",
            "d2l 1.0.3 requires matplotlib-inline==0.1.6, but you have matplotlib-inline 0.2.1 which is incompatible.\n",
            "d2l 1.0.3 requires numpy==1.23.5, but you have numpy 1.26.4 which is incompatible.\n",
            "d2l 1.0.3 requires pandas==2.0.3, but you have pandas 2.2.2 which is incompatible.\n",
            "d2l 1.0.3 requires requests==2.31.0, but you have requests 2.32.4 which is incompatible.\n",
            "d2l 1.0.3 requires scipy==1.10.1, but you have scipy 1.16.3 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.36.3 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed async-lru-2.1.0 jedi-0.19.2 json5-0.13.0 jupyter-1.1.1 jupyter-lsp-2.3.0 jupyterlab-4.5.2 jupyterlab-server-2.28.0 numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "69afdad630684b94be7cc775ef4ff33d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cpu)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1375507587.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Or CPU-only:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_installation_commands.py\u001b[0m in \u001b[0;36m_pip_magic\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;31m# Colab is set up such that pip does the right thing, and pip install\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0;31m# will properly trigger the pip install warning.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m       \u001b[0m_pip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_send_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36mprint_previous_import_warning\u001b[0;34m(output)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;34m\"\"\"Prints a warning about previously imported packages.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# display a list of packages using the colab-display-data mimetype, which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_previously_imported_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;34m\"\"\"List all previously imported packages from a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0minstalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_toplevel_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstalled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_extract_toplevel_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;34m\"\"\"Extract the list of toplevel packages associated with a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mtoplevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mtoplevel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mpackages_distributions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0mpkg_to_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_top_level_declared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_top_level_inferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m             \u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m_top_level_inferred\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    957\u001b[0m     opt_names = {\n\u001b[1;32m    958\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmodulename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malways_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m     }\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfiles\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         return skip_missing_files(\n\u001b[0m\u001b[1;32m    501\u001b[0m             make_files(\n\u001b[1;32m    502\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_files_distinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/_functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(param, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mskip_missing_files\u001b[0;34m(package_paths)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \"\"\"\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ignore_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mstat\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mdoes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \"\"\"\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# keep pip up to date\n",
        "%pip install -U pip\n",
        "\n",
        "# install d2l but skip its (too strict) dependencies\n",
        "%pip install d2l==1.0.3 --no-deps\n",
        "\n",
        "# install dependencies compatible with Python 3.12\n",
        "# NumPy >= 1.26 has Py3.12 wheels\n",
        "%pip install \"numpy>=1.26,<2\" matplotlib pandas jupyter\n",
        "\n",
        "# Choose the right index for your runtime (CPU vs CUDA). Example for CUDA 12.4:\n",
        "# %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
        "# Or CPU-only:\n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
        "\n",
        "import d2l, numpy as np\n",
        "print(\"d2l OK, numpy:\", np.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4582bdfd",
      "metadata": {
        "origin_pos": 1,
        "id": "4582bdfd"
      },
      "source": [
        "# Convolutions for Images\n",
        ":label:`sec_conv_layer`\n",
        "\n",
        "Now that we understand how convolutional layers work in theory,\n",
        "we are ready to see how they work in practice.\n",
        "Building on our motivation of convolutional neural networks\n",
        "as efficient architectures for exploring structure in image data,\n",
        "we stick with images as our running example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "07444b49",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:41:01.908966Z",
          "iopub.status.busy": "2023-08-18T19:41:01.908168Z",
          "iopub.status.idle": "2023-08-18T19:41:05.382412Z",
          "shell.execute_reply": "2023-08-18T19:41:05.381355Z"
        },
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "07444b49"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad7d3200",
      "metadata": {
        "origin_pos": 6,
        "id": "ad7d3200"
      },
      "source": [
        "## The Cross-Correlation Operation\n",
        "\n",
        "Recall that strictly speaking, convolutional layers\n",
        "are a  misnomer, since the operations they express\n",
        "are more accurately described as cross-correlations.\n",
        "Based on our descriptions of convolutional layers in :numref:`sec_why-conv`,\n",
        "in such a layer, an input tensor\n",
        "and a kernel tensor are combined\n",
        "to produce an output tensor through a (**cross-correlation operation.**)\n",
        "\n",
        "Let's ignore channels for now and see how this works\n",
        "with two-dimensional data and hidden representations.\n",
        "In :numref:`fig_correlation`,\n",
        "the input is a two-dimensional tensor\n",
        "with a height of 3 and width of 3.\n",
        "We mark the shape of the tensor as $3 \\times 3$ or ($3$, $3$).\n",
        "The height and width of the kernel are both 2.\n",
        "The shape of the *kernel window* (or *convolution window*)\n",
        "is given by the height and width of the kernel\n",
        "(here it is $2 \\times 2$).\n",
        "\n",
        "![Two-dimensional cross-correlation operation. The shaded portions are the first output element as well as the input and kernel tensor elements used for the output computation: $0\\times0+1\\times1+3\\times2+4\\times3=19$.](http://d2l.ai/_images/correlation.svg)\n",
        ":label:`fig_correlation`\n",
        "\n",
        "In the two-dimensional cross-correlation operation,\n",
        "we begin with the convolution window positioned\n",
        "at the upper-left corner of the input tensor\n",
        "and slide it across the input tensor,\n",
        "both from left to right and top to bottom.\n",
        "When the convolution window slides to a certain position,\n",
        "the input subtensor contained in that window\n",
        "and the kernel tensor are multiplied elementwise\n",
        "and the resulting tensor is summed up\n",
        "yielding a single scalar value.\n",
        "This result gives the value of the output tensor\n",
        "at the corresponding location.\n",
        "Here, the output tensor has a height of 2 and width of 2\n",
        "and the four elements are derived from\n",
        "the two-dimensional cross-correlation operation:\n",
        "\n",
        "$$\n",
        "0\\times0+1\\times1+3\\times2+4\\times3=19,\\\\\n",
        "1\\times0+2\\times1+4\\times2+5\\times3=25,\\\\\n",
        "3\\times0+4\\times1+6\\times2+7\\times3=37,\\\\\n",
        "4\\times0+5\\times1+7\\times2+8\\times3=43.\n",
        "$$\n",
        "\n",
        "Note that along each axis, the output size\n",
        "is slightly smaller than the input size.\n",
        "Because the kernel has width and height greater than $1$,\n",
        "we can only properly compute the cross-correlation\n",
        "for locations where the kernel fits wholly within the image,\n",
        "the output size is given by the input size $n_\\textrm{h} \\times n_\\textrm{w}$\n",
        "minus the size of the convolution kernel $k_\\textrm{h} \\times k_\\textrm{w}$\n",
        "via\n",
        "\n",
        "$$(n_\\textrm{h}-k_\\textrm{h}+1) \\times (n_\\textrm{w}-k_\\textrm{w}+1).$$\n",
        "\n",
        "This is the case since we need enough space\n",
        "to \"shift\" the convolution kernel across the image.\n",
        "Later we will see how to keep the size unchanged\n",
        "by padding the image with zeros around its boundary\n",
        "so that there is enough space to shift the kernel.\n",
        "Next, we implement this process in the `corr2d` function,\n",
        "which accepts an input tensor `X` and a kernel tensor `K`\n",
        "and returns an output tensor `Y`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5e550b4f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:41:05.386933Z",
          "iopub.status.busy": "2023-08-18T19:41:05.386003Z",
          "iopub.status.idle": "2023-08-18T19:41:05.393401Z",
          "shell.execute_reply": "2023-08-18T19:41:05.392355Z"
        },
        "origin_pos": 8,
        "tab": [
          "pytorch"
        ],
        "id": "5e550b4f"
      },
      "outputs": [],
      "source": [
        "def corr2d(X, K):  #@save\n",
        "    \"\"\"Compute 2D cross-correlation.\"\"\"\n",
        "    h, w = K.shape\n",
        "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
        "    for i in range(Y.shape[0]):\n",
        "        for j in range(Y.shape[1]):\n",
        "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
        "    return Y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce6cd64e",
      "metadata": {
        "origin_pos": 11,
        "id": "ce6cd64e"
      },
      "source": [
        "We can construct the input tensor `X` and the kernel tensor `K`\n",
        "from :numref:`fig_correlation`\n",
        "to [**validate the output of the above implementation**]\n",
        "of the two-dimensional cross-correlation operation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7845059c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:41:05.397828Z",
          "iopub.status.busy": "2023-08-18T19:41:05.397122Z",
          "iopub.status.idle": "2023-08-18T19:41:05.427898Z",
          "shell.execute_reply": "2023-08-18T19:41:05.426544Z"
        },
        "origin_pos": 12,
        "tab": [
          "pytorch"
        ],
        "id": "7845059c",
        "outputId": "f51d2cdf-51dd-4d8f-98a8-67a7d252279e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[19., 25.],\n",
              "        [37., 43.]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
        "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
        "corr2d(X, K)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2edc81c6",
      "metadata": {
        "origin_pos": 13,
        "id": "2edc81c6"
      },
      "source": [
        "## Convolutional Layers\n",
        "\n",
        "A convolutional layer cross-correlates the input and kernel\n",
        "and adds a scalar bias to produce an output.\n",
        "The two parameters of a convolutional layer\n",
        "are the kernel and the scalar bias.\n",
        "When training models based on convolutional layers,\n",
        "we typically initialize the kernels randomly,\n",
        "just as we would with a fully connected layer.\n",
        "\n",
        "We are now ready to [**implement a two-dimensional convolutional layer**]\n",
        "based on the `corr2d` function defined above.\n",
        "In the `__init__` constructor method,\n",
        "we declare `weight` and `bias` as the two model parameters.\n",
        "The forward propagation method\n",
        "calls the `corr2d` function and adds the bias.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "74d09a7c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:41:05.432542Z",
          "iopub.status.busy": "2023-08-18T19:41:05.431776Z",
          "iopub.status.idle": "2023-08-18T19:41:05.444669Z",
          "shell.execute_reply": "2023-08-18T19:41:05.443731Z"
        },
        "origin_pos": 15,
        "tab": [
          "pytorch"
        ],
        "id": "74d09a7c"
      },
      "outputs": [],
      "source": [
        "class Conv2D(nn.Module):\n",
        "    def __init__(self, kernel_size):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
        "        self.bias = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return corr2d(x, self.weight) + self.bias"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bddb4e9",
      "metadata": {
        "origin_pos": 18,
        "id": "1bddb4e9"
      },
      "source": [
        "In\n",
        "$h \\times w$ convolution\n",
        "or an $h \\times w$ convolution kernel,\n",
        "the height and width of the convolution kernel are $h$ and $w$, respectively.\n",
        "We also refer to\n",
        "a convolutional layer with an $h \\times w$\n",
        "convolution kernel simply as an $h \\times w$ convolutional layer.\n",
        "\n",
        "\n",
        "## Object Edge Detection in Images\n",
        "\n",
        "Let's take a moment to parse [**a simple application of a convolutional layer:\n",
        "detecting the edge of an object in an image**]\n",
        "by finding the location of the pixel change.\n",
        "First, we construct an \"image\" of $6\\times 8$ pixels.\n",
        "The middle four columns are black ($0$) and the rest are white ($1$).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3b5cdda0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:41:05.448555Z",
          "iopub.status.busy": "2023-08-18T19:41:05.447775Z",
          "iopub.status.idle": "2023-08-18T19:41:05.456977Z",
          "shell.execute_reply": "2023-08-18T19:41:05.455824Z"
        },
        "origin_pos": 19,
        "tab": [
          "pytorch"
        ],
        "id": "3b5cdda0",
        "outputId": "fa1f07a5-5cde-4539-8df4-00b2917a4ed5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "X = torch.ones((6, 8))\n",
        "X[:, 2:6] = 0\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef65b584",
      "metadata": {
        "origin_pos": 22,
        "id": "ef65b584"
      },
      "source": [
        "Next, we construct a kernel `K` with a height of 1 and a width of 2.\n",
        "When we perform the cross-correlation operation with the input,\n",
        "if the horizontally adjacent elements are the same,\n",
        "the output is 0. Otherwise, the output is nonzero.\n",
        "Note that this kernel is a special case of a finite difference operator. At location $(i,j)$ it computes $x_{i,j} - x_{(i+1),j}$, i.e., it computes the difference between the values of horizontally adjacent pixels. This is a discrete approximation of the first derivative in the horizontal direction. After all, for a function $f(i,j)$ its derivative $-\\partial_i f(i,j) = \\lim_{\\epsilon \\to 0} \\frac{f(i,j) - f(i+\\epsilon,j)}{\\epsilon}$. Let's see how this works in practice.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c64588b6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:41:05.463518Z",
          "iopub.status.busy": "2023-08-18T19:41:05.462855Z",
          "iopub.status.idle": "2023-08-18T19:41:05.467300Z",
          "shell.execute_reply": "2023-08-18T19:41:05.466485Z"
        },
        "origin_pos": 23,
        "tab": [
          "pytorch"
        ],
        "id": "c64588b6"
      },
      "outputs": [],
      "source": [
        "K = torch.tensor([[1.0, -1.0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14945056",
      "metadata": {
        "origin_pos": 24,
        "id": "14945056"
      },
      "source": [
        "We are ready to perform the cross-correlation operation\n",
        "with arguments `X` (our input) and `K` (our kernel).\n",
        "As you can see, [**we detect $1$ for the edge from white to black\n",
        "and $-1$ for the edge from black to white.**]\n",
        "All other outputs take value $0$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7287547f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:41:05.472001Z",
          "iopub.status.busy": "2023-08-18T19:41:05.471414Z",
          "iopub.status.idle": "2023-08-18T19:41:05.478644Z",
          "shell.execute_reply": "2023-08-18T19:41:05.477751Z"
        },
        "origin_pos": 25,
        "tab": [
          "pytorch"
        ],
        "id": "7287547f",
        "outputId": "723e494b-a2f3-48da-bcb0-e7553ee2a359",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "Y = corr2d(X, K)\n",
        "Y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68f25916",
      "metadata": {
        "origin_pos": 26,
        "id": "68f25916"
      },
      "source": [
        "We can now apply the kernel to the transposed image.\n",
        "As expected, it vanishes. [**The kernel `K` only detects vertical edges.**]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c5803e8e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:41:05.482194Z",
          "iopub.status.busy": "2023-08-18T19:41:05.481611Z",
          "iopub.status.idle": "2023-08-18T19:41:05.489355Z",
          "shell.execute_reply": "2023-08-18T19:41:05.488493Z"
        },
        "origin_pos": 27,
        "tab": [
          "pytorch"
        ],
        "id": "c5803e8e",
        "outputId": "ed744f40-1a51-406e-89d6-1b177abc88a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "corr2d(X.t(), K)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "231b5888",
      "metadata": {
        "origin_pos": 28,
        "id": "231b5888"
      },
      "source": [
        "## Learning a Kernel\n",
        "\n",
        "Designing an edge detector by finite differences `[1, -1]` is neat\n",
        "if we know this is precisely what we are looking for.\n",
        "However, as we look at larger kernels,\n",
        "and consider successive layers of convolutions,\n",
        "it might be impossible to specify\n",
        "precisely what each filter should be doing manually.\n",
        "\n",
        "Now let's see whether we can [**learn the kernel that generated `Y` from `X`**]\n",
        "by looking at the input--output pairs only.\n",
        "We first construct a convolutional layer\n",
        "and initialize its kernel as a random tensor.\n",
        "Next, in each iteration, we will use the squared error\n",
        "to compare `Y` with the output of the convolutional layer.\n",
        "We can then calculate the gradient to update the kernel.\n",
        "For the sake of simplicity,\n",
        "in the following\n",
        "we use the built-in class\n",
        "for two-dimensional convolutional layers\n",
        "and ignore the bias.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cc5935f0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:41:05.493184Z",
          "iopub.status.busy": "2023-08-18T19:41:05.492373Z",
          "iopub.status.idle": "2023-08-18T19:41:05.588165Z",
          "shell.execute_reply": "2023-08-18T19:41:05.586875Z"
        },
        "origin_pos": 30,
        "tab": [
          "pytorch"
        ],
        "id": "cc5935f0",
        "outputId": "2a9b9b2a-1d46-4ed7-ffda-796a43ed55b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2, loss 2.487\n",
            "epoch 4, loss 0.449\n",
            "epoch 6, loss 0.088\n",
            "epoch 8, loss 0.020\n",
            "epoch 10, loss 0.006\n"
          ]
        }
      ],
      "source": [
        "# Construct a two-dimensional convolutional layer with 1 output channel and a\n",
        "# kernel of shape (1, 2). For the sake of simplicity, we ignore the bias here\n",
        "conv2d = nn.LazyConv2d(1, kernel_size=(1, 2), bias=False)\n",
        "\n",
        "# The two-dimensional convolutional layer uses four-dimensional input and\n",
        "# output in the format of (example, channel, height, width), where the batch\n",
        "# size (number of examples in the batch) and the number of channels are both 1\n",
        "X = X.reshape((1, 1, 6, 8))\n",
        "Y = Y.reshape((1, 1, 6, 7))\n",
        "lr = 3e-2  # Learning rate\n",
        "\n",
        "for i in range(10):\n",
        "    Y_hat = conv2d(X)\n",
        "    l = (Y_hat - Y) ** 2\n",
        "    conv2d.zero_grad()\n",
        "    l.sum().backward()\n",
        "    # Update the kernel\n",
        "    conv2d.weight.data[:] -= lr * conv2d.weight.grad\n",
        "    if (i + 1) % 2 == 0:\n",
        "        print(f'epoch {i + 1}, loss {l.sum():.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be06b7e7",
      "metadata": {
        "origin_pos": 33,
        "id": "be06b7e7"
      },
      "source": [
        "Note that the error has dropped to a small value after 10 iterations. Now we will [**take a look at the kernel tensor we learned.**]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4ab76f3e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:41:05.593720Z",
          "iopub.status.busy": "2023-08-18T19:41:05.592926Z",
          "iopub.status.idle": "2023-08-18T19:41:05.601680Z",
          "shell.execute_reply": "2023-08-18T19:41:05.600494Z"
        },
        "origin_pos": 35,
        "tab": [
          "pytorch"
        ],
        "id": "4ab76f3e",
        "outputId": "dda99f83-186f-4003-bac2-b8a3d135b032",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.9983, -0.9858]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "conv2d.weight.data.reshape((1, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc14c622",
      "metadata": {
        "origin_pos": 38,
        "id": "fc14c622"
      },
      "source": [
        "Indeed, the learned kernel tensor is remarkably close\n",
        "to the kernel tensor `K` we defined earlier.\n",
        "\n",
        "## Cross-Correlation and Convolution\n",
        "\n",
        "Recall our observation from :numref:`sec_why-conv` of the correspondence\n",
        "between the cross-correlation and convolution operations.\n",
        "Here let's continue to consider two-dimensional convolutional layers.\n",
        "What if such layers\n",
        "perform strict convolution operations\n",
        "as defined in :eqref:`eq_2d-conv-discrete`\n",
        "instead of cross-correlations?\n",
        "In order to obtain the output of the strict *convolution* operation, we only need to flip the two-dimensional kernel tensor both horizontally and vertically, and then perform the *cross-correlation* operation with the input tensor.\n",
        "\n",
        "It is noteworthy that since kernels are learned from data in deep learning,\n",
        "the outputs of convolutional layers remain unaffected\n",
        "no matter such layers\n",
        "perform\n",
        "either the strict convolution operations\n",
        "or the cross-correlation operations.\n",
        "\n",
        "To illustrate this, suppose that a convolutional layer performs *cross-correlation* and learns the kernel in :numref:`fig_correlation`, which is here denoted as the matrix $\\mathbf{K}$.\n",
        "Assuming that other conditions remain unchanged,\n",
        "when this layer instead performs strict *convolution*,\n",
        "the learned kernel $\\mathbf{K}'$ will be the same as $\\mathbf{K}$\n",
        "after $\\mathbf{K}'$ is\n",
        "flipped both horizontally and vertically.\n",
        "That is to say,\n",
        "when the convolutional layer\n",
        "performs strict *convolution*\n",
        "for the input in :numref:`fig_correlation`\n",
        "and $\\mathbf{K}'$,\n",
        "the same output in :numref:`fig_correlation`\n",
        "(cross-correlation of the input and $\\mathbf{K}$)\n",
        "will be obtained.\n",
        "\n",
        "In keeping with standard terminology in deep learning literature,\n",
        "we will continue to refer to the cross-correlation operation\n",
        "as a convolution even though, strictly-speaking, it is slightly different.\n",
        "Furthermore,\n",
        "we use the term *element* to refer to\n",
        "an entry (or component) of any tensor representing a layer representation or a convolution kernel.\n",
        "\n",
        "\n",
        "## Feature Map and Receptive Field\n",
        "\n",
        "As described in :numref:`subsec_why-conv-channels`,\n",
        "the convolutional layer output in\n",
        ":numref:`fig_correlation`\n",
        "is sometimes called a *feature map*,\n",
        "as it can be regarded as\n",
        "the learned representations (features)\n",
        "in the spatial dimensions (e.g., width and height)\n",
        "to the subsequent layer.\n",
        "In CNNs,\n",
        "for any element $x$ of some layer,\n",
        "its *receptive field* refers to\n",
        "all the elements (from all the previous layers)\n",
        "that may affect the calculation of $x$\n",
        "during the forward propagation.\n",
        "Note that the receptive field\n",
        "may be larger than the actual size of the input.\n",
        "\n",
        "Let's continue to use :numref:`fig_correlation` to explain the receptive field.\n",
        "Given the $2 \\times 2$ convolution kernel,\n",
        "the receptive field of the shaded output element (of value $19$)\n",
        "is\n",
        "the four elements in the shaded portion of the input.\n",
        "Now let's denote the $2 \\times 2$\n",
        "output as $\\mathbf{Y}$\n",
        "and consider a deeper CNN\n",
        "with an additional $2 \\times 2$ convolutional layer that takes $\\mathbf{Y}$\n",
        "as its input, outputting\n",
        "a single element $z$.\n",
        "In this case,\n",
        "the receptive field of $z$\n",
        "on $\\mathbf{Y}$ includes all the four elements of $\\mathbf{Y}$,\n",
        "while\n",
        "the receptive field\n",
        "on the input includes all the nine input elements.\n",
        "Thus,\n",
        "when any element in a feature map\n",
        "needs a larger receptive field\n",
        "to detect input features over a broader area,\n",
        "we can build a deeper network.\n",
        "\n",
        "\n",
        "Receptive fields derive their name from neurophysiology.\n",
        "A series of experiments on a range of animals using different stimuli\n",
        ":cite:`Hubel.Wiesel.1959,Hubel.Wiesel.1962,Hubel.Wiesel.1968` explored the response of what is called the visual\n",
        "cortex on said stimuli. By and large they found that lower levels respond to edges and related\n",
        "shapes. Later on, :citet:`Field.1987` illustrated this effect on natural\n",
        "images with, what can only be called, convolutional kernels.\n",
        "We reprint a key figure in :numref:`field_visual` to illustrate the striking similarities.\n",
        "\n",
        "![Figure and caption taken from :citet:`Field.1987`: An example of coding with six different channels. (Left) Examples of the six types of sensor associated with each channel. (Right) Convolution of the image in (Middle) with the six sensors shown in (Left). The response of the individual sensors is determined by sampling these filtered images at a distance proportional to the size of the sensor (shown with dots). This diagram shows the response of only the even symmetric sensors.](https://github.com/d2l-ai/d2l-pytorch-colab/blob/master/img/field-visual.png?raw=1)\n",
        ":label:`field_visual`\n",
        "\n",
        "As it turns out, this relation even holds for the features computed by deeper layers of networks trained on image classification tasks, as demonstrated in, for example, :citet:`Kuzovkin.Vicente.Petton.ea.2018`. Suffice it to say, convolutions have proven to be an incredibly powerful tool for computer vision, both in biology and in code. As such, it is not surprising (in hindsight) that they heralded the recent success in deep learning.\n",
        "\n",
        "## Summary\n",
        "\n",
        "The core computation required for a convolutional layer is a cross-correlation operation. We saw that a simple nested for-loop is all that is required to compute its value. If we have multiple input and multiple output channels, we are  performing a matrix--matrix operation between channels. As can be seen, the computation is straightforward and, most importantly, highly *local*. This affords significant hardware optimization and many recent results in computer vision are only possible because of that. After all, it means that chip designers can invest in fast computation rather than memory when it comes to optimizing for convolutions. While this may not lead to optimal designs for other applications, it does open the door to ubiquitous and affordable computer vision.\n",
        "\n",
        "In terms of convolutions themselves, they can be used for many purposes, for example detecting edges and lines, blurring images, or sharpening them. Most importantly, it is not necessary that the statistician (or engineer) invents suitable filters. Instead, we can simply *learn* them from data. This replaces feature engineering heuristics by evidence-based statistics. Lastly, and quite delightfully, these filters are not just advantageous for building deep networks but they also correspond to receptive fields and feature maps in the brain. This gives us confidence that we are on the right track.\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Construct an image `X` with diagonal edges.\n",
        "    1. What happens if you apply the kernel `K` in this section to it?\n",
        "    1. What happens if you transpose `X`?\n",
        "    1. What happens if you transpose `K`?\n",
        "1. Design some kernels manually.\n",
        "    1. Given a directional vector $\\mathbf{v} = (v_1, v_2)$, derive an edge-detection kernel that detects\n",
        "       edges orthogonal to $\\mathbf{v}$, i.e., edges in the direction $(v_2, -v_1)$.\n",
        "    1. Derive a finite difference operator for the second derivative. What is the minimum\n",
        "       size of the convolutional kernel associated with it? Which structures in images respond most strongly to it?\n",
        "    1. How would you design a blur kernel? Why might you want to use such a kernel?\n",
        "    1. What is the minimum size of a kernel to obtain a derivative of order $d$?\n",
        "1. When you try to automatically find the gradient for the `Conv2D` class we created, what kind of error message do you see?\n",
        "1. How do you represent a cross-correlation operation as a matrix multiplication by changing the input and kernel tensors?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db5fe222",
      "metadata": {
        "origin_pos": 40,
        "tab": [
          "pytorch"
        ],
        "id": "db5fe222"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/66)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def corr2d_custom(X, K):\n",
        "    \"\"\"Compute 2D cross-correlation.\"\"\"\n",
        "    h, w = K.shape\n",
        "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
        "    for i in range(Y.shape[0]):\n",
        "        for j in range(Y.shape[1]):\n",
        "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
        "\n",
        "    print(Y)\n",
        "    return Y"
      ],
      "metadata": {
        "id": "DMnQnZ92BJ2e"
      },
      "id": "DMnQnZ92BJ2e",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 1\n",
        "import numpy as np\n",
        "\n",
        "X = np.array([\n",
        "    [1,0,0,0,0],\n",
        "    [1,1,0,0,0],\n",
        "    [1,1,1,0,0],\n",
        "    [1,1,1,1,0],\n",
        "    [1,1,1,1,1]\n",
        "])\n",
        "\n",
        "K = np.array([\n",
        "    [1,0,-1],\n",
        "    [1,0,-1],\n",
        "    [1,0,-1]\n",
        "])\n",
        "\n",
        "corr2d_custom(X, K)\n",
        "\n",
        "# Response không bằng 0, không mạnh, không sắc nét do biên chéo trong X có thành phần biên chéo, không tạo thành một đưởng rõ ràng trong feature\n",
        "# => Mỗi kernel chỉ phản ứng với 1 orientation nhất định, cụ thể"
      ],
      "metadata": {
        "id": "XUP0ghA_ATZv",
        "outputId": "aebd6644-c46a-4db1-8a60-c3ca4d134aa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "XUP0ghA_ATZv",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2., 2., 1.],\n",
            "        [1., 2., 2.],\n",
            "        [0., 1., 2.]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 2., 1.],\n",
              "        [1., 2., 2.],\n",
              "        [0., 1., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transpose X and K\n",
        "X_T = X.T\n",
        "K_T = K.T\n",
        "\n",
        "corr2d_custom(X_T, K) # đổi hướng edge chéo từ 45 độ sang -45\n",
        "corr2d_custom(X, K_T) # đổi kernel từ vertical edge detector sang horizontal edge detector\n",
        "\n",
        "# Transpose kernel ≠ convolution, Convolution chuẩn yêu cầu flip kernel cả ngang(fliplr) lẫn dọc(flipud)\n",
        "K_conv = np.flipud(np.fliplr(K))\n",
        "corr2d_custom(X, K_conv)"
      ],
      "metadata": {
        "id": "5E1o68cgA3db",
        "outputId": "af740801-9cbf-4bcf-b77c-701fade6d62c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5E1o68cgA3db",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-2., -1.,  0.],\n",
            "        [-2., -2., -1.],\n",
            "        [-1., -2., -2.]])\n",
            "tensor([[-2., -2., -1.],\n",
            "        [-1., -2., -2.],\n",
            "        [ 0., -1., -2.]])\n",
            "tensor([[-2., -2., -1.],\n",
            "        [-1., -2., -2.],\n",
            "        [ 0., -1., -2.]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2., -2., -1.],\n",
              "        [-1., -2., -2.],\n",
              "        [ 0., -1., -2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 2\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "v1, v2 = 1, 2\n",
        "Kx = np.array([[-1, 0, 1]])\n",
        "Ky = np.array([[-1], [0], [1]])\n",
        "\n",
        "K = v2 * Kx - v1 * Ky # edge vuông góc với v nên sẽ tìm được đạo hàm trên edge có vector là v2, -v1"
      ],
      "metadata": {
        "id": "-zBLwPs7Cp26"
      },
      "id": "-zBLwPs7Cp26",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Từ cách triển khai Taylor ta sẽ tìm được kernel cho đạo hàm bậc hai là [1, -2, 1].\n",
        "=> Thường sẽ dùng common 3 x 3 Laplacian kernel:\n",
        "laplacian = np.array([\n",
        "    [ 0,  1,  0],\n",
        "    [ 1, -4,  1],\n",
        "    [ 0,  1,  0]\n",
        "]).\n",
        "\n",
        "Minimum kernel size: 3 x 3\n",
        "Strongest response: thin edges (ở bốn góc cạnh), points of rapid intensity change and noise."
      ],
      "metadata": {
        "id": "KnO_ZPYaF2WM"
      },
      "id": "KnO_ZPYaF2WM"
    },
    {
      "cell_type": "code",
      "source": [
        "# Blur kernel = local average -> low-pass filter (bộ lọc thông thấp, triển khai bằng cách lấy TB local)\n",
        "blur = np.ones((3,3)) / 9\n",
        "\n",
        "# Gaussian blur: sum of elements = 16, get local average\n",
        "gaussian = np.array([\n",
        "    [1, 2, 1],\n",
        "    [2, 4, 2],\n",
        "    [1, 2, 1]\n",
        "]) / 16\n",
        "\n",
        "# Meaning: reduce noise, anti-aliasing, preprocessing before edge detection, biological plausibility (tính hợp lý sinh học) cụ thể biểu hiện thông qua việc áp dụng điều kiện lên trên 1 vùng local input để tiến hành weight sharing khi filter trượt trên ảnh (triển khai receptive field + translation invariance)"
      ],
      "metadata": {
        "id": "LW1BHqmBHjuH"
      },
      "id": "LW1BHqmBHjuH",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Derivative order.   Minimum kernel size\n",
        "1st.                2 or 3\n",
        "2nd                 3\n",
        "d-th                d + 1\n",
        "\n",
        "Answer: minimum d + 1"
      ],
      "metadata": {
        "id": "brIcaUHSI_RV"
      },
      "id": "brIcaUHSI_RV"
    },
    {
      "cell_type": "markdown",
      "source": [
        ". Exercise 3: Gradient error when implementing Conv2D manually by using: loss.backward() -> find and update gradient\n",
        "\n",
        "Errors:\n",
        "- RuntimeError: element 0 of tensors does not require grad\n",
        "- RuntimeError: one of the variables needed for gradient computation has been modified\n",
        "\n",
        "Why this happens cause:\n",
        "\t•\tUse NumPy instead of torch ops\n",
        "\t•\tIn-place operations\n",
        "\t•\t.detach() implicitly (ngầm định sử dụng detach)\n",
        "\t•\tAutograd cannot build a computation graph (sử dụng auto grad sẽ không thể tiến hành được đồ thị tính toán tìm gradient)\n",
        "\n",
        "  Ví dụ:\n",
        "import torch\n",
        "\n",
        "x = torch.randn(1, requires_grad=True) # manually grad, use torch operations\n",
        "y = x.numpy() # convert back to using numpy, break autograd cause it can not build manual grad in\n"
      ],
      "metadata": {
        "id": "RRbF4BR7JYYD"
      },
      "id": "RRbF4BR7JYYD"
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 4: vec(Y) = W.im2col(X) where im2col: column of patches\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "X = np.array([\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9]\n",
        "])\n",
        "\n",
        "K = np.array([\n",
        "    [1, 0],\n",
        "    [0, -1]\n",
        "])\n",
        "\n",
        "# Apply kernel 2 x 2 one by one for local kernel at position (0,0): 1, 2,4,5 then position (0,1): [2,3,5,6],...\n",
        "patches = np.array([\n",
        "    [1, 2, 4, 5],\n",
        "    [2, 3, 5, 6],\n",
        "    [4, 5, 7, 8],\n",
        "    [5, 6, 8, 9]\n",
        "])\n",
        "\n",
        "# Flatten\n",
        "kernel_vec = K.flatten()\n",
        "\n",
        "# Perform matrix multiplication\n",
        "Y = patches @ kernel_vec\n",
        "print(kernel_vec)\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "PT-0O3h3KRso",
        "outputId": "4155162a-a419-42d7-ae87-4fde3539b287",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "PT-0O3h3KRso",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1  0  0 -1]\n",
            "[-4 -4 -4 -4]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}